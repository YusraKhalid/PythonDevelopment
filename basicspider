import json
import scrapy

from urlparse import urljoin
from w3lib.html import remove_tags


class BasicSpider(scrapy.Spider):
    name = 'basic'
    allowed_domains = ['www.aboutyou.at',
                       'api.aboutyou.at']
    start_url = 'https://www.aboutyou.at'

    def __init__(self):
        self.depth = 1
        self.pages = 1
        self.locale = None
        self.product_variants = ["brand",
                                 "defaultImage",
                                 "defaultVariant",
                                 "variants",
                                 "variants.images",
                                 "variants.sizes",
                                 "modelImage",
                                 "styles.defaultImage",
                                 "styles.modelImage",
                                 "styles.product-details.attributeGroups",
                                 "styles.product-details.images",
                                 "styles.product-details.model-information",
                                 "product-details.attributeGroups",
                                 "product-details.images",
                                 "product-details.model-information",
                                 ]

    def start_requests(self):
        yield scrapy.Request(url=self.start_url, callback=self.gender_switch)

    def gender_switch(self, response):
        genders = response.css('.styles__genderSwitch--3jvXr a::attr(href)').extract()
        for gender in genders:
            absolute_url = urljoin(self.start_url, gender)
            yield scrapy.Request(absolute_url, callback=self.get_initial_state, meta={'gender': gender})

    def get_initial_state(self, response):
        """
        Get the initial state of the website in a json format.
        """
        initial_state = response.xpath('//*[contains(text(), "window.__INITIAL_STATE__")]').extract_first()
        initial_state = remove_tags(initial_state).replace('window.__INITIAL_STATE__=', '').rstrip(";")
        initial_state = json.loads(initial_state.encode('utf8'))
        self.locale = initial_state['urlManager']['locale']
        return self.crawl(initial_state, response.meta['gender'])

    def crawl(self, initial_state, user):
        all_active_categories = initial_state['entities']['categories']
        category_ids = self.get_category_ids(all_active_categories, user)
        category_products_api = 'https://api.aboutyou.at/products?filter[category]={id}&page[number]={page}'
        # Horizontal Crawling
        for ID in category_ids:
            for page in range(1, self.pages+1):
                url = category_products_api.format(id=ID, page=page)
                yield scrapy.Request(url, callback=self.category_products)

    def get_category_ids(self, all_active_categories, user_url):
        """
        The method gets all the category IDs
        Depth determines the subcategory against each URL, for which data is to be retrieved
        Depth 0 : /frauen
        Depth 1 : /frauen/shoes, /frauen/clothes, ...
        Depth 2 : /frauen/shoes/new, /frauen/shoes/sneakers, ...
        """
        category_ids = []
        for category in all_active_categories:
            if all_active_categories[category]['url'] == user_url:  # Get starting point
                category_ids.append(category)
                break

        for _ in range(self.depth):
            children_ids = []
            for parent_id in category_ids:
                category_ids.remove(parent_id)
                children_ids += all_active_categories[parent_id]['childrenIds']
            category_ids += children_ids
        return category_ids

    def category_products(self, response):
        products_details_api = 'https://api.aboutyou.at/products/{}?include=' + ','.join(self.product_variants)
        all_products = json.loads(response.body.encode('utf8'))
        for product in all_products['data']:
            yield scrapy.Request(products_details_api.format(product['id']), callback=self.parse)

    def parse(self, response):
        pass
    #  Code for parsing the product is below and incomplete

    #     product = json.loads(response.body.encode('utf8'))
    #     product_attributes = product['data']['attributes']
    #     print("Product ID", product['data']['id'])
    #     print("Product URL", product_attributes['url'])
    #     print("Name", product_attributes['name'])
    #     print("Locale", self.locale)
    #     product_relationships = product['data']['relationships']
    #     relationship_details = product['included']
    #     brand_id = product_relationships['brand']['data']['id']
    #     brand_name = self.get_brand_name(relationship_details, brand_id)
    #
    # def get_brand_name(self, data, id):
    #     for information in data:
    #         if information['id'] == id:
    #             return information['attributes']['name']
    #     return "aboutyou.to"

